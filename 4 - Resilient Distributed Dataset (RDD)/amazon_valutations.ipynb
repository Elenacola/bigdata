{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisi di 22.5 Milioni di valutazioni di libri su Amazon\n",
    "In questo notebook utilizzeremo un RDD di Spark per analizzare circa 22.5 milioni di valutazioni di libri prese da Amazon.com.\n",
    "<br>\n",
    "Le domande alla quale risponderemo sono le seguenti."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Quante valutazioni ci sono nel dataset ?\n",
    "* Quanti libri ci sono nel dataset ?\n",
    "* Quante valutazioni ha ricevuto ogni libro ?\n",
    "* Quali sono i 10 libri più valutati ?\n",
    "* Qual è la valutazione media per ogni libro ?\n",
    "* Quali sono i 10 libri con la valutazione più alta ?\n",
    "* Chi sono i 10 recensori più critici ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procuriamoci il Dataset\n",
    "Per prima cosa procuriamoci il dataset scaricandolo il locale, il dataset si trova in formato CSV a [questo link](http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/ratings_Books.csv), esegui il comando qui sotto per scaricarlo direttamente da Jupyter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-07-04 10:05:54--  http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/ratings_Books.csv\n",
      "Resolving snap.stanford.edu (snap.stanford.edu)... 171.64.75.80\n",
      "Connecting to snap.stanford.edu (snap.stanford.edu)|171.64.75.80|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 916259348 (874M) [text/csv]\n",
      "Saving to: ‘ratings_Books.csv.1’\n",
      "\n",
      "ratings_Books.csv.1 100%[===================>] 873.81M  3.52MB/s    in 4m 8s   \n",
      "\n",
      "2019-07-04 10:10:02 (3.52 MB/s) - ‘ratings_Books.csv.1’ saved [916259348/916259348]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/ratings_Books.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inizializziamo Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf().setMaster(\"local\").setAppName(\"AmazonReviews\")\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importiamo il CSV dentro un RDD\n",
    "Per caricare un qualsiasi file di testo dentro un RDD possiamo usare il metodo *.textFile(path)* della nostra istanza della classe SparkContext."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewsRDD = sc.textFile(\"ratings_Books.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vediamo un po' cosa contiene l'RDD. Avendo 22.5 milioni di elementi, utilizzare il metodo *.collect()* è sconveniente per ovvie ragioni, al suo posto possiamo usare il metodo *.take(n)* per selezionare soltanto n elementi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AH2L9G3DQHHAJ,0000000116,4.0,1019865600',\n",
       " 'A2IIIDRK3PRRZY,0000000116,1.0,1395619200',\n",
       " 'A1TADCM7YWPQ8M,0000000868,4.0,1031702400',\n",
       " 'AWGH7V0BDOJKB,0000013714,4.0,1383177600',\n",
       " 'A3UTQPQPM4TQO0,0000013714,5.0,1374883200']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviewsRDD.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ogni elemento di ogni riga corrisponde a (in ordine):\n",
    "* Id dell'utente che ha lasciato la valutazione.\n",
    "* Id del libro recensito.\n",
    "* Valutazione da 1.0 a 5.0.\n",
    "* Timestamp di quando è stata lasciata la recensione.\n",
    "\n",
    "Per ovvi motivi di privacy non ci è possibile risalire ad un utente partendo dal suo ID, mentre per il libro è possibile farlo aggiungendo l'ID a questo url https://www.amazon.com/dp/, ad esempio per il primo elemento: https://www.amazon.com/dp/0000000116\n",
    "<br><br>\n",
    "**NOTA BENE** Sì lo so, se hai cliccato sul link ti sei trovato una penna e non un libro come abbiamo detto, il motivo è che tale penna è stata inserita impropriamente nella categoria libri di Amazon, quindi tutto in regola per noi :)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contiamo il numero totale di valutazioni\n",
    "Per contare il numero di recensioni usiamo semplicemente il metodo *.count()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22507155"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviewsRDD.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quindi in realtà sono più di 2.5 milioni di libri nel dataset, buono a sapersi :D."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contiamo le valutazioni per ogni libro\n",
    "Per contare le valutazioni che ogni libro ha ricevuto creiamo un nuovo RDD contenente soltanto gli ID dei libri per ogni riga. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0000000116', '0000000116', '0000000868', '0000013714', '0000013714']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "productsRDD = reviewsRDD.map(lambda x: x.split(\",\")[1])\n",
    "productsRDD.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poi usiamo semplicemente il metodo *.countByValue()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "productsCount = productsRDD.countByValue()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stampiamo il numero di valutazioni ricevute per i primi 10 libri."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID LIBRO\tCONTEGGIO\n",
      "0000000116\t2\n",
      "0000000868\t1\n",
      "0000013714\t14\n",
      "0000015393\t1\n",
      "0000029831\t5\n",
      "0000038504\t2\n",
      "0000041696\t4\n",
      "0000095699\t1\n",
      "0000174076\t1\n",
      "0000202010\t1\n",
      "0000230022\t10\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "print(\"ID LIBRO\\tCONTEGGIO\")\n",
    "for product_id, count in productsCount.items():\n",
    "    print(\"%s\\t%s\" % (product_id, count))\n",
    "    if(i>=10):\n",
    "        break\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troviamo i 10 libri più valutati\n",
    "Per trovare i 10 libri più valutati potremmo semplicemente utilizzare il defaultdict ottenuto sopra, però voglio farti vedere un'altro modo per farlo !\n",
    "<br>\n",
    "Mappiamo ogni elemento ad una lista, contenente l'elemento stesso ed un valore 1 (lo so sembra una cosa senza senso, ma è un'operazione tipica del processo map-reduce, ora capirai perché)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0000000116', 1),\n",
       " ('0000000116', 1),\n",
       " ('0000000868', 1),\n",
       " ('0000013714', 1),\n",
       " ('0000013714', 1)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "productsCount = productsRDD.map(lambda x: (x, 1))\n",
    "productsCount.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizziamo il metodo *reduceByKey* per sommare i valori degli elementi aventi la stessa chiave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0001006657', 2),\n",
       " ('0001922408', 2),\n",
       " ('0002000601', 6),\n",
       " ('0002006650', 2),\n",
       " ('0002007770', 6001)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "productsCount = productsCount.reduceByKey(lambda x, y: x+y)\n",
    "productsCount.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capito il trucchetto ? Riducendo l'RDD tramite una somma dei valori 1 che abbiamo aggiunto prima abbiamo ottenuto la somma totale delle valutazioni per ogni libro. Ora ci basta ordinarli in senso decrescente e tenere stampare i primi 10 risultati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0439023483', 21398),\n",
       " ('030758836X', 19867),\n",
       " ('0439023513', 14114),\n",
       " ('0385537859', 12973),\n",
       " ('0007444117', 12629),\n",
       " ('0375831002', 12571),\n",
       " ('038536315X', 12564),\n",
       " ('0345803485', 12290),\n",
       " ('0316055433', 11746),\n",
       " ('0849922070', 10424)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "productsCountSorted = productsCount.sortBy(lambda x: x[1], ascending=False)\n",
    "productsCountSorted.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecco qui i 10 libri più recensiti, qui possiamo vedere i primi 3:\n",
    "* https://www.amazon.com/dp/0439023483\n",
    "* https://www.amazon.com/dp/030758836X\n",
    "* https://www.amazon.com/dp/0439023513\n",
    "\n",
    "Il primo è The Hunger Games, leggilo se non lo hai già fatto (o al massimo guarda il film).\n",
    "<br><br>\n",
    "**NOTA BENE**\n",
    "<br>\n",
    "Se il numero delle valutazione che vedi nel sito dovesse essere superiore rispetto a quello riportato dalla nostra analisi, non preoccuparti, non abbiamo fatto nulla di sbagliato, semplicemente gli utenti di Amazon hanno lasciato nuove valutazioni rispetto a quando il dataset che stiamo usando è stato creato."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcoliamo la valutazione media\n",
    "Per calcolare la valutazione media creiamo un nuovo RDD contenete soltanto ID del libro e valutazione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0000000116', 4.0),\n",
       " ('0000000116', 1.0),\n",
       " ('0000000868', 4.0),\n",
       " ('0000013714', 4.0),\n",
       " ('0000013714', 5.0)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parseProductRating(row):\n",
    "    columns = row.split(\",\")\n",
    "    product = columns[1]\n",
    "    rating = float(columns[2])\n",
    "    \n",
    "    return (product, rating)\n",
    "\n",
    "productsRDD = reviewsRDD.map(parseProductRating)\n",
    "productsRDD.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proviamo a somamre il totale delle valutazioni usando il metodo reduceByKey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0001006657', 10.0),\n",
       " ('0001922408', 10.0),\n",
       " ('0002000601', 23.0),\n",
       " ('0002006650', 8.0),\n",
       " ('0002007770', 26398.0)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratingSumRDD = productsRDD.reduceByKey(lambda x,y: x+y)\n",
    "ratingSumRDD.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ora dovremmo dividere per il numero di valutazioni che ogni libro ha ricevuto, ma eseguendo la riduzione abbiamo perso questa informazione, quindi non è la cosa giusta da fare.\n",
    "<br><br>\n",
    "Proviamo in un'altro modo, mappiamo ogni elemento ad una lista, contenente l'elemento stesso ed un valore 1 che ci servirà come contatore, esattamente come fatto in precedenza, poi eseguiamo la riduzione per chiave sommando sia i contatori che le valutazione come fatto appena sopra. Per non farci mancare niente (e per non mettere troppi RDD in memoria) facciamo tutto in un unica istruzione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0001006657', (10.0, 2)),\n",
       " ('0001922408', (10.0, 2)),\n",
       " ('0002000601', (23.0, 6)),\n",
       " ('0002006650', (8.0, 2)),\n",
       " ('0002007770', (26398.0, 6001))]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratingSumRDD = productsRDD.mapValues(lambda x: (x,1)).reduceByKey(lambda x, y: (x[0]+y[0], x[1]+y[1]))\n",
    "ratingSumRDD.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfetto ! Ora abbiamo sia la somma che il conteggio, quindi possiamo eseguire un map di nuovo, dividendo il secondo per il primo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0001006657', 5.0),\n",
       " ('0001922408', 5.0),\n",
       " ('0002000601', 3.8333333333333335),\n",
       " ('0002006650', 4.0),\n",
       " ('0002007770', 4.398933511081486)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratingMeanRDD = ratingSumRDD.mapValues(lambda x: x[0]/x[1])\n",
    "ratingMeanRDD.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troviamo i 10 libri con la valutazione più alta\n",
    "Per trovare i libri con la valutazione più alta potremmo semplicemente ordinare l'RDD calcolato appena sopra, però otterremo dei risulati falsati, dato che libri che hanno ottenuto un'unica valutazione a 5 stelle saranno alle prime posizioni. Quindi facciamo una cosa più intelligente considerando solo i libri che sono stati valutati almeno 100 volte.<br><br>\n",
    "Calcoliamo nuovamente la valutazione media per ogni libro, questa volta però teniamo anche il conteggio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0001006657', (5.0, 2)),\n",
       " ('0001922408', (5.0, 2)),\n",
       " ('0002000601', (3.8333333333333335, 6)),\n",
       " ('0002006650', (4.0, 2)),\n",
       " ('0002007770', (4.398933511081486, 6001))]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratingMeanRDD = ratingSumRDD.mapValues(lambda x: (x[0]/x[1], x[1]))\n",
    "ratingMeanRDD.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtriamo i libri, tenendo soltanto quelli che hanno avuto almeno 100 valutazioni, per curiosità contiamo quanti sono."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29296"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratingMeanRDD = ratingMeanRDD.filter(lambda x: x[1][1]>=100)\n",
    "ratingMeanRDD.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quasi 3mila, non pochi ! Ora ordiniamo quest'ultimo RDD in base alla valutazione media e stampiamo i primi 10 risultati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0983408904', (5.0, 128)),\n",
       " ('0830766316', (5.0, 103)),\n",
       " ('0972394648', (4.992647058823529, 136)),\n",
       " ('1499390165', (4.991803278688525, 122)),\n",
       " ('0849381185', (4.990566037735849, 106)),\n",
       " ('0757317723', (4.9862068965517246, 145)),\n",
       " ('1939629071', (4.983193277310924, 119)),\n",
       " ('1499381921', (4.982857142857143, 350)),\n",
       " ('1616387165', (4.981308411214953, 107)),\n",
       " ('0814416993', (4.980769230769231, 104))]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratingSortedRDD = ratingMeanRDD.sortBy(lambda x: x[1][0], ascending=False)\n",
    "ratingSortedRDD.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ed ecco qui le valutazioni medie per ogni libro !\n",
    "\n",
    "Ecco qui i 10 libri più recensiti, qui possiamo vedere i primi 3:\n",
    "* https://www.amazon.com/dp/0983408904\n",
    "* https://www.amazon.com/dp/0830766316\n",
    "* https://www.amazon.com/dp/0972394648\n",
    "<br><br>\n",
    "\n",
    "**NOTA BENE**\n",
    "<br>\n",
    "Ovviamente sarebbe stato più intelligente eseguire la riduzione tenendo anche il conteggio la prima volta, quando abbiamo calcolato la valutazione media per libro per rispondere alla domanda precedente, in modo tale da non dover rieseguire un'operazione abbastanza dispendiosa, ma dato che il nostro scopo è imparare abbiamo fatto meglio a far così :)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troviamo i 10 recensori più critici\n",
    "Cerchiamo i 10 recensori più critici, cioè quelli che sono soliti lasciare le recensioni più basse, per farlo calcoliamo la valutazione media lasciata da ogni recensore e ordiniamo l'RDD così ottenuto in maniera ascendente. Il processo è quasi identico a quello che abbiamo già eseguito per ottenere i libri con la valutazione maggiore.\n",
    "<br><br>\n",
    "Comciamo creando un nuovo dataset contenente soltanto id utente come chiave e valutazione e 1 come valore, l'1 ci serve sempre come contatore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('AH2L9G3DQHHAJ', (4.0, 1)),\n",
       " ('A2IIIDRK3PRRZY', (1.0, 1)),\n",
       " ('A1TADCM7YWPQ8M', (4.0, 1)),\n",
       " ('AWGH7V0BDOJKB', (4.0, 1)),\n",
       " ('A3UTQPQPM4TQO0', (5.0, 1))]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parseReviewerRating(row):\n",
    "    columns = row.split(\",\")\n",
    "    reviewer = columns[0]\n",
    "    rating = float(columns[2])\n",
    "    \n",
    "    return (reviewer, (rating, 1))\n",
    "\n",
    "reviewerRDD = reviewsRDD.map(parseReviewerRating)\n",
    "reviewerRDD.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E sommiamo tutte le valutazioni e il contatore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A2742OG8PK8KU6', (10.0, 2)),\n",
       " ('A2GKR2Q7MD8DG4', (12.0, 3)),\n",
       " ('A1MC4E00RO5E9T', (17.0, 4)),\n",
       " ('A3IKTM9D8RVWKU', (5.0, 1)),\n",
       " ('A3UZSIDE90JWW1', (5.0, 1))]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviewerRDD = reviewerRDD.reduceByKey(lambda x, y: (x[0]+y[0], x[1]+y[1]))\n",
    "reviewerRDD.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anche in questo caso, per evitare di ottenere soltanto i recensori che hanno lasciato un'unica valutazione, filtriamo il dataframe tenendo soltanto i recensori che hanno lasciato almeno 100 valutazioni."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11244"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviewerRDD = reviewerRDD.filter(lambda x: x[1][1]>100)\n",
    "reviewerRDD.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ne abbiamo oltre 11mila, vediamo tra questi chi sono i più cattivi, calcoliamo la loro valutazione media."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A8IPQ1Q1O7YX5', 4.227048371174728),\n",
       " ('A2PN65B6BSTIYZ', 3.953271028037383),\n",
       " ('AX724J32HPG1J', 4.184738955823293),\n",
       " ('AFFGYGNO989PD', 4.2785714285714285),\n",
       " ('A1WCJEZS66D224', 3.5789473684210527)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criticalReviewerRDD = reviewerRDD.mapValues(lambda x: x[0]/x[1])\n",
    "criticalReviewerRDD.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordiniamo il dataset così ottenuto in maniera ascendente e stampiamo i primi 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('AH62BQTCMR3BR', 1.0534188034188035),\n",
       " ('A186OSXC7LHJDB', 1.2014925373134329),\n",
       " ('A2HESNQJZ9OB7H', 1.2543859649122806),\n",
       " ('A36IQRD3B5MK8G', 1.505050505050505),\n",
       " ('A3JF63XRSLLH0P', 1.5648148148148149),\n",
       " ('A344N0X5LIV43M', 1.646551724137931),\n",
       " ('A1SS16UHYW77D4', 1.855421686746988),\n",
       " ('A19UFCMSFGOZ2K', 2.076923076923077),\n",
       " ('A1NJHOGKZZRAX8', 2.1588785046728973),\n",
       " ('A1ZY08GYVIKZFM', 2.2446043165467624)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criticalReviewerSortedRDD = criticalReviewerRDD.sortBy(lambda x: x[1])\n",
    "criticalReviewerSortedRDD.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AH62BQTCMR3BR sei una brutta perzona !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
