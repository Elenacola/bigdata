{"cells":[{"cell_type":"markdown","source":["# Regressione Logistica con Spark MLlib\nIn questo notebook vedremo come eseguire una semplice classificazione, utilizzando un modello di Regressione Logistica con il modulo MLlib di Spark. Il modello che andremo ha creare ha lo scopo di identificare tumori al seno maligni da delle informazioni estratte da delle agobiopsie."],"metadata":{}},{"cell_type":"markdown","source":["## Procuriamoci il Dataset e importiamolo in un DataFrame\nPossiamo scaricare il Dataset da [quesa pagina su Kaggle](https://www.kaggle.com/uciml/breast-cancer-wisconsin-data) e utilizziamolo per creare una tabella su Databricks. Una volta fatto importiamolo in un DataFrame usando una query SQL."],"metadata":{}},{"cell_type":"code","source":["cancer_df = spark.sql(\"SELECT * FROM breast_cancer_csv\")\ncancer_df.columns"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">5</span><span class=\"ansired\">]: </span>\n[&apos;mean radius&apos;,\n &apos;mean texture&apos;,\n &apos;mean perimeter&apos;,\n &apos;mean area&apos;,\n &apos;mean smoothness&apos;,\n &apos;mean compactness&apos;,\n &apos;mean concavity&apos;,\n &apos;mean concave points&apos;,\n &apos;mean symmetry&apos;,\n &apos;mean fractal dimension&apos;,\n &apos;radius error&apos;,\n &apos;texture error&apos;,\n &apos;perimeter error&apos;,\n &apos;area error&apos;,\n &apos;smoothness error&apos;,\n &apos;compactness error&apos;,\n &apos;concavity error&apos;,\n &apos;concave points error&apos;,\n &apos;symmetry error&apos;,\n &apos;fractal dimension error&apos;,\n &apos;worst radius&apos;,\n &apos;worst texture&apos;,\n &apos;worst perimeter&apos;,\n &apos;worst area&apos;,\n &apos;worst smoothness&apos;,\n &apos;worst compactness&apos;,\n &apos;worst concavity&apos;,\n &apos;worst concave points&apos;,\n &apos;worst symmetry&apos;,\n &apos;worst fractal dimension&apos;,\n &apos;malignant&apos;]\n</div>"]}}],"execution_count":3},{"cell_type":"markdown","source":["Il DataFrame ha 31 colonne:\n* 30 features: che rappresentano delle proprietà dell'immagine, come raggio, area e perimetro.\n* 1 target: che è la colonna malignant, un valore di 1 indica un tumore maligno, al contrario un valore di 0 indica un tumore benigno."],"metadata":{}},{"cell_type":"markdown","source":["## Preprocessing dei dati\n%md La classe MLlib richiede che le features si trovino tutte all'interno di un unico vettore su di una colonna, possiamo creare questa rappresentazione utilizzando la classe *VectorAssemlber* di MLlib:\n* All'interno del parametro inputCols dobbiamo specificare quali sono le colonne con gli input.\n* All'interno del parametro outputCol dobbiamo specificare il nome della colonna che conterrà le features."],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.feature import VectorAssembler\n\nassembler = VectorAssembler(inputCols=cancer_df.columns[:-1], outputCol=\"features\")\ndata_df = assembler.transform(cancer_df)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":6},{"cell_type":"markdown","source":["%md E' buona norma portare le features in un range di valori comuni, questo processo può velocizzare anche di molto la fase di addestramento. Facciamolo tramite la **standardizzazione** che ci permette di contenere le varie colonne all'interno di una distribuzione normale, cioè una distribuzione con media 0 e deviazione standard 1. Possiamo eseguire la standardizzazione usando la classe *StandardScaler* di MLlib."],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.feature import StandardScaler\n\nscaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\")\nscaler_model = scaler.fit(data_df)\ndata_df = scaler_model.transform(data_df)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":8},{"cell_type":"markdown","source":["Ora possiamo creare i DataFrame per addestramento e test, estraendoli dal Dataframe originale, possiamo farlo tramite il metodo RandomSplit. Assegnamo il 70% degli esempi al set di addestramento e il 30% al set di test."],"metadata":{}},{"cell_type":"code","source":["train_set, test_set = data_df.randomSplit([0.7, 0.3])\n\nprint(\"%d esempi nel train set\" % train_set.count())\nprint(\"%d esempi nel test set\" % test_set.count())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">393 esempi nel train set\n170 esempi nel test set\n</div>"]}}],"execution_count":10},{"cell_type":"markdown","source":["Ottimo ! Ora possiamo creare il modello di Regressione Logistica, usiamo la classe *LogisticRegression, all'interno del costruttore dovremo passare due parametri:\n* **featuresCol**: il nome della colonna con le features\n* **labelCol**: il nome della colonna con il target"],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.classification import LogisticRegression\n\nlr = LogisticRegression(featuresCol=\"scaled_features\", labelCol=\"malignant\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":12},{"cell_type":"markdown","source":["Avviamo l'addestramento con il metodo *fit*, passando al suo interno il set di addetramento"],"metadata":{}},{"cell_type":"code","source":["model = lr.fit(train_set)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":14},{"cell_type":"markdown","source":["Abbiamo creato il nostro modello ! Ora verifichiamone la qualità."],"metadata":{}},{"cell_type":"markdown","source":["## Valutiamo il Modello\nOra verifichiamone la qualità testandolo su dati che non ha visto durante l'addestramento, possiamo farlo usando il test set e il metodo *evalualte*."],"metadata":{}},{"cell_type":"code","source":["evaluation = model.evaluate(test_set)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":17},{"cell_type":"markdown","source":["Il metodo *evaluate* calcolerà diverse metriche che ci possono aiutare a comprendere la qualità del modello, vediamone alcune."],"metadata":{}},{"cell_type":"markdown","source":["#### Accuracy (Accuratezza)\nL'accuracy indica semplicemente la percentuale di classificazioni che il nostro modello ha eseguito correttamente."],"metadata":{}},{"cell_type":"code","source":["evaluation.accuracy"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">10</span><span class=\"ansired\">]: </span>0.956989247311828\n</div>"]}}],"execution_count":20},{"cell_type":"markdown","source":["### Precision (Precision)\nLa precision ci dice, tra le classificazioni eseguite per una data classe, quante sono effettivamente apparteneti a quella classe."],"metadata":{}},{"cell_type":"code","source":["evaluation.precisionByLabel"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">37</span><span class=\"ansired\">]: </span>[0.9545454545454546, 0.9519230769230769]\n</div>"]}}],"execution_count":22},{"cell_type":"markdown","source":["### Recall (Richiamo)\nIl recall ci dice quanti dei casi positivi il modello è riuscito a classificare correttamente."],"metadata":{}},{"cell_type":"code","source":["evaluation.recallByLabel"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">40</span><span class=\"ansired\">]: </span>[0.9264705882352942, 0.9705882352941176]\n</div>"]}}],"execution_count":24},{"cell_type":"markdown","source":["## Testiamo il modello\nOra che abbiamo addestrato e validato il nostro modello, testiamolo su nuovi dati. Una clinica ci invia un file CSV contenente i risultati dell'agobiopsia per 6 pazienti che hanno in cura, dobbiamo utilizzare il nostro modello per identificare eventuali tumori maligni. Scarichiamo  il CSV"],"metadata":{}},{"cell_type":"code","source":["!wget https://raw.githubusercontent.com/ProfAI/bigdata/master/7%20-%20Machine%20Learning%20Supervisionato%20-%20Classificazione/data/exam_results.csv"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":26},{"cell_type":"markdown","source":["Carichiamolo all'interno di un DataFrame."],"metadata":{}},{"cell_type":"code","source":["exams_df = spark.read.csv(\"file:/databricks/driver/exam_results.csv\", inferSchema=True, header=True)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":28},{"cell_type":"markdown","source":["Creiamo la colonna con le features"],"metadata":{}},{"cell_type":"code","source":["new_data_df = assembler.transform(exams_df)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":30},{"cell_type":"markdown","source":["Eseguiamo la standardizzazione"],"metadata":{}},{"cell_type":"code","source":["new_data_df = scaler_model.transform(new_data_df"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":32},{"cell_type":"markdown","source":["E otteniamo le predizioni usando il metodo *transform* del modello"],"metadata":{}},{"cell_type":"code","source":["pred_df = model.transform(new_data_df)\npred_df.columns"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">33</span><span class=\"ansired\">]: </span>\n[&apos;mean radius&apos;,\n &apos;mean texture&apos;,\n &apos;mean perimeter&apos;,\n &apos;mean area&apos;,\n &apos;mean smoothness&apos;,\n &apos;mean compactness&apos;,\n &apos;mean concavity&apos;,\n &apos;mean concave points&apos;,\n &apos;mean symmetry&apos;,\n &apos;mean fractal dimension&apos;,\n &apos;radius error&apos;,\n &apos;texture error&apos;,\n &apos;perimeter error&apos;,\n &apos;area error&apos;,\n &apos;smoothness error&apos;,\n &apos;compactness error&apos;,\n &apos;concavity error&apos;,\n &apos;concave points error&apos;,\n &apos;symmetry error&apos;,\n &apos;fractal dimension error&apos;,\n &apos;worst radius&apos;,\n &apos;worst texture&apos;,\n &apos;worst perimeter&apos;,\n &apos;worst area&apos;,\n &apos;worst smoothness&apos;,\n &apos;worst compactness&apos;,\n &apos;worst concavity&apos;,\n &apos;worst concave points&apos;,\n &apos;worst symmetry&apos;,\n &apos;worst fractal dimension&apos;,\n &apos;features&apos;,\n &apos;scaled_features&apos;,\n &apos;rawPrediction&apos;,\n &apos;probability&apos;,\n &apos;prediction&apos;]\n</div>"]}}],"execution_count":34},{"cell_type":"markdown","source":["Come vedi il DataFrame risultante contiene due nuove colonne:\n* **Prediction**: che contiene il label (0=benigno, 1=maligno)\n* **Probabily**: che contiene la probabilità di apparteneza alle due classi."],"metadata":{}},{"cell_type":"code","source":["pred_df.select([\"probability\", \"prediction\"]).show(6, False)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------------------------------------------+----------+\nprobability                               |prediction|\n+------------------------------------------+----------+\n[1.0,0.0]                                 |0.0       |\n[1.7432636933686846E-244,1.0]             |1.0       |\n[7.453405721620013E-205,1.0]              |1.0       |\n[1.0,0.0]                                 |0.0       |\n[0.9999999999999991,8.075319188159663E-16]|0.0       |\n[1.0,3.984631167625693E-159]              |0.0       |\n+------------------------------------------+----------+\n\n</div>"]}}],"execution_count":36},{"cell_type":"markdown","source":["Due dei tumori sono stati etichettati come maligni, con delle probabilità associate molto alte, sarebbe il caso che la clinica effettuasse ulteriori esami."],"metadata":{}}],"metadata":{"name":"logistic_regression","notebookId":2246374182813684},"nbformat":4,"nbformat_minor":0}
